{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaFKQHNT8nnS"
   },
   "source": [
    "Using publicly available data at data.gov.sg please create a model pipeline to forecast (upcoming 3 hours) the traffic flow at the specified location (latitude: 1.357098686 longitude: 103.902042), for a specified time of day. The solution must have the following components:\n",
    "\n",
    "1. Estimation of historical traffic flow, using image data sets available here (https://data.gov.sg/dataset/traffic-images )\n",
    "\n",
    "2. Use the pipeline from (1) and weather data (https://data.gov.sg/dataset/realtime-weather-readings), to forecast the traffic flow at the specified location at a specified time of day\n",
    "\n",
    "Notes: You may use any additional data sources / APIs to build your models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I am running this code on Google Colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcGdG1FURHZm",
    "outputId": "e2c6c063-b385-4784-c544-a691172b03af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cvlib\n",
      "  Downloading cvlib-0.2.7.tar.gz (13.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.1 MB 4.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cvlib) (1.21.5)\n",
      "Collecting progressbar\n",
      "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cvlib) (2.23.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from cvlib) (7.1.2)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from cvlib) (2.4.1)\n",
      "Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (from cvlib) (0.5.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cvlib) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cvlib) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cvlib) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cvlib) (2.10)\n",
      "Building wheels for collected packages: cvlib, progressbar\n",
      "  Building wheel for cvlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cvlib: filename=cvlib-0.2.7-py3-none-any.whl size=10046385 sha256=27e9a2e3b4cb3315c408606c14b1c78c3c9bafc49e06275c4bf01fb7342d6c22\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/d7/31/bc643bd3a8b11a7368b1ab1d8a6299b33b462ed0b0683ddc5a\n",
      "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=2b31946b6a079ee81b8b6e366643879acff525f09be6a6c56c4aa8e21d1c5882\n",
      "  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n",
      "Successfully built cvlib progressbar\n",
      "Installing collected packages: progressbar, cvlib\n",
      "Successfully installed cvlib-0.2.7 progressbar-2.5\n",
      "Requirement already satisfied: pystan==2.19.1.1 in /usr/local/lib/python3.7/dist-packages (2.19.1.1)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (1.21.5)\n",
      "Requirement already satisfied: Cython!=0.25.1,>=0.22 in /usr/local/lib/python3.7/dist-packages (from pystan==2.19.1.1) (0.29.28)\n",
      "Collecting prophet\n",
      "  Downloading prophet-1.0.1.tar.gz (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 2.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.29.28)\n",
      "Collecting cmdstanpy==0.9.68\n",
      "  Downloading cmdstanpy-0.9.68-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 4.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pystan~=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.19.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.3.5)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (3.2.2)\n",
      "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.0.9)\n",
      "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.4.0)\n",
      "Requirement already satisfied: holidays>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.10.5.2)\n",
      "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (4.62.3)\n",
      "Collecting ujson\n",
      "  Downloading ujson-5.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->prophet) (0.5.11)\n",
      "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (0.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (1.15.0)\n",
      "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (2.2.3)\n",
      "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet) (4.1.3)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet) (2018.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (3.0.7)\n",
      "Building wheels for collected packages: prophet\n",
      "  Building wheel for prophet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for prophet: filename=prophet-1.0.1-py3-none-any.whl size=6639353 sha256=2d54072e85a01c5726d3533dae3723922e3f7cc6591aa267e3c3f9ac247b845d\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/a0/1a/02c9ec9e3e9de6bdbb3d769d11992a6926889d71567d6b9b67\n",
      "Successfully built prophet\n",
      "Installing collected packages: ujson, cmdstanpy, prophet\n",
      "  Attempting uninstall: cmdstanpy\n",
      "    Found existing installation: cmdstanpy 0.9.5\n",
      "    Uninstalling cmdstanpy-0.9.5:\n",
      "      Successfully uninstalled cmdstanpy-0.9.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fbprophet 0.7.1 requires cmdstanpy==0.9.5, but you have cmdstanpy 0.9.68 which is incompatible.\u001b[0m\n",
      "Successfully installed cmdstanpy-0.9.68 prophet-1.0.1 ujson-5.1.0\n",
      "Requirement already satisfied: opencv-python==4.1.2.30 in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python==4.1.2.30) (1.21.5)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cvlib\n",
    "!pip install pystan==2.19.1.1\n",
    "!pip install prophet\n",
    "!pip install opencv-python==4.1.2.30\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j9rPigInFzoL"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import requests, json, joblib\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import urllib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from google.colab.patches import cv2_imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wawe8KsqULuC",
    "outputId": "80e4699b-552d-424a-be5d-c2529bfd2bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqCcYiyWTx2z",
    "outputId": "0d0afea7-7be6-40ee-c4c7-7b4da89e5981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the system paths:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/content',\n",
       " '/env/python',\n",
       " '/usr/lib/python37.zip',\n",
       " '/usr/lib/python3.7',\n",
       " '/usr/lib/python3.7/lib-dynload',\n",
       " '/usr/local/lib/python3.7/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " '/content/gdrive/My Drive/Colab Notebooks/Interviews/Siemens/data/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/Interviews/Siemens/data/')\n",
    "print(\"All the system paths:\")\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "KHEyrHd3T_l6",
    "outputId": "ebb360a7-ec0e-456f-f0ce-282303337f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/gdrive/My Drive/Colab Notebooks/Interviews/Siemens/data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/content/gdrive/My Drive/Colab Notebooks/Interviews/Siemens/data/')\n",
    "print(\"Current working directory:\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjIjYbX_VMIr"
   },
   "source": [
    "## Define `cv2plt` for image display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZonhTYkGVJ_w"
   },
   "outputs": [],
   "source": [
    "def cv2plt(img):\n",
    "    plt.figure(figsize=(8,8))        # To change the size of figure\n",
    "    plt.axis('off')\n",
    "    if np.size(img.shape) == 3:\n",
    "        plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(img,cmap='gray',vmin=0,vmax=255)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RY1wgF0PUzVk"
   },
   "source": [
    "# Using YOLO v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6MkYvxIRTZK"
   },
   "outputs": [],
   "source": [
    "lbl_file        = 'yolov3.txt'\n",
    "classes         = open(lbl_file).read().strip().split(\"\\n\")\n",
    "\n",
    "                                                # Read in the deep learning net\n",
    "yoloconfig      = 'yolov3.cfg'\n",
    "yoloweights     = 'yolov3.weights'\n",
    "net             = cv2.dnn.readNet(yoloweights,yoloconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQTq3v8DU4za"
   },
   "outputs": [],
   "source": [
    "def getOutputLayers(net):\n",
    "    layers = net.getLayerNames()\n",
    "    outLayers = [layers[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return outLayers\n",
    "\n",
    "\n",
    "def yoloV3Detect(img,scFactor=1/255,nrMean=(0,0,0),RBSwap=True,scoreThres=0.5,nmsThres=0.4):\n",
    "    blob = cv2.dnn.blobFromImage(image=img,\n",
    "                                 scalefactor=scFactor,\n",
    "                                 size=(416,416),\n",
    "                                 mean=nrMean,\n",
    "                                 swapRB=RBSwap,\n",
    "                                 crop=False)\n",
    "  \n",
    "    imgHeight = img.shape[0]\n",
    "    imgWidth = img.shape[1]\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outLyrs = getOutputLayers(net)\n",
    "    preds = net.forward(outLyrs)\n",
    "\n",
    "    classId = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    fboxes=[]\n",
    "    fclasses=[]\n",
    "\n",
    "    for scale in preds:\n",
    "      for pred in scale:\n",
    "        scores = pred[5:]\n",
    "        clss = np.argmax(scores)\n",
    "        confidence = scores[clss]\n",
    "\n",
    "        if confidence > 0.5:\n",
    "          xc = int(pred[0]*imgWidth)\n",
    "          yc = int(pred[1]*imgHeight)\n",
    "          w = int(pred[2]*imgWidth)\n",
    "          h = int(pred[3]*imgHeight)\n",
    "          x = xc - w/2\n",
    "          y = yc - h/2\n",
    "\n",
    "          classId.append(clss)\n",
    "          confidences.append(float(confidence))\n",
    "          boxes.append([x, y, w, h])\n",
    "      \n",
    "    selected = cv2.dnn.NMSBoxes(bboxes=boxes,\n",
    "                                scores=confidences,\n",
    "                                score_threshold=scoreThres,\n",
    "                                nms_threshold=nmsThres)\n",
    "  \n",
    "  # return empty list \n",
    "    if(len(selected) < 1):\n",
    "      return [fboxes, fclasses]\n",
    "  \n",
    "    for j in selected[:,0]:\n",
    "      fboxes.append(boxes[j])\n",
    "      fclasses.append(classId[j])\n",
    "\n",
    "    return [fboxes, fclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9EcKDXrU_ca"
   },
   "outputs": [],
   "source": [
    "def pltDetect(img, fboxes, fclasses, classes):\n",
    "    colorset = np.random.uniform(0, \n",
    "                                 255,\n",
    "                                 size=(len(classes), 3))\n",
    "    txtlbl = \"\"\n",
    "  \n",
    "    for count, fbox in enumerate(fboxes):\n",
    "      x = int(fbox[0])\n",
    "      y = int(fbox[1])\n",
    "      w = int(fbox[2])\n",
    "      h = int(fbox[3])\n",
    "\n",
    "      color  = colorset[fclasses[count]]\n",
    "      txtlbl = str(classes[fclasses[count]])\n",
    "\n",
    "      cv2.rectangle(img,\n",
    "                    (x,y),\n",
    "                    (x+w, y+h),\n",
    "                    color,\n",
    "                    2)\n",
    "    \n",
    "      cv2.putText(img,\n",
    "                  txtlbl,\n",
    "                  (x,y-5),\n",
    "                  cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                  0.5,\n",
    "                  color,\n",
    "                  1,\n",
    "                  cv2.LINE_AA)\n",
    "      \n",
    "      #cv2plt(img)\n",
    "\n",
    "      # return number of cars detected\n",
    "      return (txtlbl.count('car'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEBsXH5UG44-"
   },
   "outputs": [],
   "source": [
    "def url_to_image(url):\n",
    "    # download the image, convert it to a NumPy array, and then read\n",
    "    # it into OpenCV format\n",
    "    resp = requests.get(url).content\n",
    "    image = np.asarray(bytearray(resp), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # return the image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1HmIt1s6CZN"
   },
   "outputs": [],
   "source": [
    "def getVehicleCount(retrievalTime):\n",
    "    url_traffic = 'https://api.data.gov.sg/v1/transport/traffic-images'\n",
    "\n",
    "    params = {\"date_time\": retrievalTime.strftime(\"%Y-%m-%dT%H:%M:%S\")}\n",
    "\n",
    "    print(params)\n",
    "\n",
    "    data = json.loads(requests.get(url_traffic, params=params).content)\n",
    "\n",
    "    # Get image URL for the requested location\n",
    "    try:\n",
    "        url = [d.get('image', None) for d in data['items'][0]['cameras'] if d.get('location', None) == {'latitude': 1.357098686, 'longitude': 103.902042}][0]\n",
    "    except:\n",
    "        print(\"Unable to get data for {0}\".format(retrievalTime))\n",
    "        return -1 # Invalid Data\n",
    "\n",
    "    image = url_to_image(url)\n",
    "    cv2plt(image)\n",
    "\n",
    "    [fboxes, fclasses] = yoloV3Detect(image)\n",
    "    pltDetect(image, fboxes, fclasses, classes)\n",
    "\n",
    "    return (len(fboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rx4tolo6DlZK"
   },
   "outputs": [],
   "source": [
    "def getVehicleCountFile(imageFile):\n",
    "    image = cv2.imread(imageFile)\n",
    "    # cv2plt(image)\n",
    "\n",
    "    [fboxes, fclasses] = yoloV3Detect(image)\n",
    "    pltDetect(image, fboxes, fclasses, classes)\n",
    "\n",
    "    return (len(fboxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4Xk4_jVW-6I"
   },
   "source": [
    "**Nearest Weather Station will be 36 Kim Chuan Road**\n",
    "Device ID: S43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-WZQO72cMSg"
   },
   "outputs": [],
   "source": [
    "def getRainfall(retrievalTime):\n",
    "    url_weather = 'https://api.data.gov.sg/v1/environment/rainfall'\n",
    "    params = {\"date_time\": retrievalTime.strftime(\"%Y-%m-%dT%H:%M:%S\")} \n",
    "\n",
    "    data_weather = json.loads(requests.get(url_weather, params=params).content)\n",
    "\n",
    "    # Get rainfall for the requested location\n",
    "    try:\n",
    "        rainfall = [d.get('value', None) for d in data_weather.get('items')[0].get('readings') if d.get('station_id', None) == \"S43\"][0]\n",
    "    except:\n",
    "        print(\"Unable to get data for {0}\".format(retrievalTime))\n",
    "        return -1 # Invalid Data\n",
    "\n",
    "    return rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OhlH5D0-TH9"
   },
   "outputs": [],
   "source": [
    "# This method will run inference on images already pulled from DataGov\n",
    "\n",
    "# Declare Empty DataFrame\n",
    "train_df = pd.DataFrame(columns=['Datetime', 'Vehicle Count'])\n",
    "\n",
    "for root, dirs, files in os.walk('images'):\n",
    "    files.sort()\n",
    "    for filename in files[8618:]:\n",
    "        imgFile = os.path.join(root, filename)\n",
    "        print(filename)\n",
    "        vehicleCount = getVehicleCountFile(imgFile)\n",
    "        a_series = pd.Series([filename, vehicleCount], index = train_df.columns)\n",
    "        train_df = train_df.append(a_series, ignore_index=True)\n",
    "        train_df['Datetime'] = train_df['Datetime'].str.replace(\".jpg\", \"\").str.replace(\"T\", \" \")\n",
    "        #train_df['Datetime'] = pd.to_datetime(train_df.Datetime,format='%Y-%m-d %H-%M-%S')\n",
    "        train_df.to_excel(\"DataGov.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "anpGhACGVj4D"
   },
   "outputs": [],
   "source": [
    "# This method will take long time. As it run inference as it is pulling image data from DataGov\n",
    "\n",
    "# Declare Empty DataFrame\n",
    "train_df = pd.DataFrame(columns=['Datetime', 'Vehicle Count', 'Rainfall'])\n",
    "\n",
    "start = datetime.now().replace(month=1, day=1, hour=0, minute=0, second=0)\n",
    "\n",
    "for dy in range(365, -1, -1):\n",
    "    whichday = start - timedelta(days=dy)\n",
    "    for hr in range(24):\n",
    "        print(\"Iteration {} {}\".format(dy, hr))\n",
    "        now = whichday + timedelta(hours=hr)\n",
    "        vehicleCount = getVehicleCount(now)\n",
    "        rainfall = getRainfall(now)\n",
    "        print(\"Vehicle Count is {0}.\".format(vehicleCount))\n",
    "        print(\"Rainfall is {0} mm\".format(rainfall))\n",
    "        a_series = pd.Series([now, vehicleCount, rainfall], index = train_df.columns)\n",
    "        train_df = train_df.append(a_series, ignore_index=True)\n",
    "        train_df['Datetime'] = pd.to_datetime(train_df.Datetime,format='%d-%m-%Y %H:%M') \n",
    "    train_df.to_excel(\".\\DataGov.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To pull latest past 3 hour data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method will take long time. As it run inference as it is pulling image data from DataGov\n",
    "def getLastData(retrievalTime):\n",
    "    train_df = pd.DataFrame(columns=['Datetime', 'Rainfall', 'Vehicle Count'])\n",
    "\n",
    "    for hr in range(3, 0, -1):\n",
    "        print(\"Iteration {}\".format(hr))\n",
    "        now = retrievalTime - timedelta(hours=hr)\n",
    "        rainfall = getRainfall(now)\n",
    "        vehicleCount = getVehicleCount(now)\n",
    "        print(\"Rainfall is {0} mm\".format(rainfall))\n",
    "        print(\"Vehicle Count is {0}.\".format(vehicleCount))\n",
    "        now = now.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "        a_series = pd.Series([now, rainfall, vehicleCount], index = train_df.columns)\n",
    "        train_df = train_df.append(a_series, ignore_index=True)\n",
    "\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wZXqvcJCVYa"
   },
   "source": [
    "# We are using **Prophet** to do Time Series Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T00:56:01.092660Z",
     "iopub.status.busy": "2022-03-02T00:56:01.092397Z",
     "iopub.status.idle": "2022-03-02T00:56:02.228995Z",
     "shell.execute_reply": "2022-03-02T00:56:02.227912Z",
     "shell.execute_reply.started": "2022-03-02T00:56:01.092622Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel('train.xlsx')\n",
    "print(train.head())\n",
    "print(\"***\")\n",
    "print(train.tail())\n",
    "print(\"***\")\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgp = pytz.timezone('Asia/Singapore')\n",
    "d = datetime.datetime.now(sgp)\n",
    "train = pd.concat([train, getLastData(d)])\n",
    "print(train.tail())\n",
    "train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T00:56:02.230931Z",
     "iopub.status.busy": "2022-03-02T00:56:02.230643Z",
     "iopub.status.idle": "2022-03-02T00:56:02.561130Z",
     "shell.execute_reply": "2022-03-02T00:56:02.559619Z",
     "shell.execute_reply.started": "2022-03-02T00:56:02.230894Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot_date(train['Datetime'], train['Vehicle Count'], fmt=\"b-\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T00:56:02.564165Z",
     "iopub.status.busy": "2022-03-02T00:56:02.563783Z",
     "iopub.status.idle": "2022-03-02T00:56:02.784654Z",
     "shell.execute_reply": "2022-03-02T00:56:02.782963Z",
     "shell.execute_reply.started": "2022-03-02T00:56:02.564123Z"
    }
   },
   "outputs": [],
   "source": [
    "train.columns = ['ds', 'rainfall', 'y']\n",
    "train['ds']= pd.to_datetime(train['ds'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T00:56:43.260812Z",
     "iopub.status.busy": "2022-03-02T00:56:43.260475Z",
     "iopub.status.idle": "2022-03-02T00:56:48.077749Z",
     "shell.execute_reply": "2022-03-02T00:56:48.076876Z",
     "shell.execute_reply.started": "2022-03-02T00:56:43.260781Z"
    }
   },
   "outputs": [],
   "source": [
    "m = Prophet(changepoint_prior_scale=0.01)\n",
    "m.add_country_holidays(country_name='SG')\n",
    "m.add_regressor('rainfall')\n",
    "m.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T01:01:58.264557Z",
     "iopub.status.busy": "2022-03-02T01:01:58.263356Z",
     "iopub.status.idle": "2022-03-02T01:01:58.281312Z",
     "shell.execute_reply": "2022-03-02T01:01:58.280847Z",
     "shell.execute_reply.started": "2022-03-02T01:01:58.264492Z"
    }
   },
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=3, freq='H')\n",
    "future['rainfall'] = train['rainfall']\n",
    "future.loc[-3:, 'rainfall'] = train.iloc[-1]['rainfall']\n",
    "future.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T01:02:59.348150Z",
     "iopub.status.busy": "2022-03-02T01:02:59.347802Z",
     "iopub.status.idle": "2022-03-02T01:03:06.061079Z",
     "shell.execute_reply": "2022-03-02T01:03:06.059586Z",
     "shell.execute_reply.started": "2022-03-02T01:02:59.348117Z"
    }
   },
   "outputs": [],
   "source": [
    "fcst = m.predict(future)\n",
    "fig = m.plot(fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T01:06:23.420221Z",
     "iopub.status.busy": "2022-03-02T01:06:23.419953Z",
     "iopub.status.idle": "2022-03-02T01:06:23.558863Z",
     "shell.execute_reply": "2022-03-02T01:06:23.557734Z",
     "shell.execute_reply.started": "2022-03-02T01:06:23.420194Z"
    }
   },
   "outputs": [],
   "source": [
    "fcst['yhat'] = fcst['yhat'].clip(lower=0).round()\n",
    "fcst['yhat'] = fcst['yhat'].astype(int)\n",
    "print(fcst.describe())\n",
    "print(\"**\")\n",
    "print(fcst.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T01:19:48.031862Z",
     "iopub.status.busy": "2022-03-02T01:19:48.031480Z",
     "iopub.status.idle": "2022-03-02T01:19:49.627020Z",
     "shell.execute_reply": "2022-03-02T01:19:49.626090Z",
     "shell.execute_reply.started": "2022-03-02T01:19:48.031827Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = m.plot_components(fcst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation\n",
    "1. Number of cars using this expressway was trending down from 2021 to 2022\n",
    "2. Highest usage is on Saturday \n",
    "3. Peak hour usually occurs about close to 9am and close to 5pm, which can be explained to start and end of working hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Prediction for next 3 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-02T01:15:22.129809Z",
     "iopub.status.busy": "2022-03-02T01:15:22.129492Z",
     "iopub.status.idle": "2022-03-02T01:15:22.140725Z",
     "shell.execute_reply": "2022-03-02T01:15:22.139730Z",
     "shell.execute_reply.started": "2022-03-02T01:15:22.129779Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction = fcst.tail(3)['yhat'].reset_index()\n",
    "\n",
    "print(\"Prediction of number of cars for next 3 hours: \\r\\nHour 1: {0} \\r\\nHour 2: {1} \\r\\nHour 3: {2}\".format(prediction.iloc[0].yhat, prediction.iloc[1].yhat,prediction.iloc[2].yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEQ9q4F-DkBm"
   },
   "source": [
    "# Enhancements to be made:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "342bqwvDDoK-"
   },
   "source": [
    "1. Include pre-Holiday effect (e.g. Christmas eve, New Year Eve etc.): include columns lower_window and upper_window which extend the holiday out \n",
    "2. Get weather prediction (convert descriptive text from Data.Gov to quantitative rainfall)\n",
    "3. Saving of Prophet model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TrafficFlowPredictor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
